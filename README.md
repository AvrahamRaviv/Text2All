# Text2All

A curated list of text-based generative models resources

## Table of contents
**[Works and Papers](#Works-and-Papers)**

**[Tutorials](#Tutorials)**

## Works and Papers

### Text-to-Image
[DALL-E - Hierarchical Text-Conditional Image Generation with CLIP Latents](https://openai.com/dall-e-2/)

[Imagen - Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](https://imagen.research.google/)

[Stable Diffusion - High-Resolution Image Synthesis with Latent Diffusion Models](https://github.com/CompVis/stable-diffusion)

[MidJourney](https://www.midjourney.com/home/)

[DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://dreambooth.github.io/)

[Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors](https://arxiv.org/abs/2203.13131)

### Text-to-Video
[Make-A-Video: Text-to-Video Generation without Text-Video Data](https://makeavideo.studio/)

[Imagen Video: High Definition Video Generation With Diffusion Models](https://imagen.research.google/video/)

### Text-to-3D
[DreamFusion](https://dreamfusionpaper.github.io/)

### Text-to-Audio
[AudioGen: Textually Guided Audio Generation](https://felixkreuk.github.io/text2audio_arxiv_samples/)

### Text-to-Human-Motion
[Human Motion Diffusion Model](https://paperswithcode.com/paper/human-motion-diffusion-model)

## Tutorials
